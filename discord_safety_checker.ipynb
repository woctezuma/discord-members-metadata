{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "AOetn6xSNb68",
        "RMgR2SgkNmDC",
        "izHCcUs0eIoJ",
        "eZTDk2I9KMVA"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Filter inappropriate content\n",
        "\n",
        "- https://github.com/woctezuma/discord-members-metadata"
      ],
      "metadata": {
        "id": "QAF5wev8M7fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages"
      ],
      "metadata": {
        "id": "AOetn6xSNb68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet transformers detoxify mediapy"
      ],
      "metadata": {
        "id": "hydcX-K-FVhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the image dataset"
      ],
      "metadata": {
        "id": "RMgR2SgkNmDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "for i in range(1, 3):\n",
        "  fname = f\"img_{i}.zip\"\n",
        "\n",
        "  !curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/img/{fname}\n",
        "  !unzip -qq {fname}"
      ],
      "metadata": {
        "id": "SL7A0j_WNhnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the text datasets"
      ],
      "metadata": {
        "id": "izHCcUs0eIoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "!curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/bio/bios.json\n",
        "!curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/metadata/members.json"
      ],
      "metadata": {
        "id": "MTW4Yo7keMXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define utils"
      ],
      "metadata": {
        "id": "eZTDk2I9KMVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def save_to_json(data, fname):\n",
        "  with Path(fname).open('w') as f:\n",
        "    json.dump(data, f, indent=True)\n",
        "\n",
        "def load_from_json(fname):\n",
        "  with Path(fname).open() as f:\n",
        "    data = json.load(f)\n",
        "  return data\n",
        "\n",
        "def safe_load_from_json(fname):\n",
        "  try:\n",
        "    data = load_from_json(fname)\n",
        "  except FileNotFoundError:\n",
        "    data = {}\n",
        "  return data"
      ],
      "metadata": {
        "id": "h-CfckeOKOJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def get_member_id(image_path):\n",
        "  return Path(image_path).stem"
      ],
      "metadata": {
        "id": "DlczHCyo1FuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output_fname(pipe, suffix = \"\", ext = \".json\"):\n",
        "  return pipe.model.name_or_path.replace('/', '_') + f'{suffix}{ext}'"
      ],
      "metadata": {
        "id": "F7tpp7ZLesfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_detoxify_results(detoxify_results : dict, model_type: str = \"\", data_type: str =\"\"):\n",
        "  # This fixes:\n",
        "  # > TypeError: Object of type float32 is not JSON serializable\n",
        "  dd = {}\n",
        "  for k,v in detoxify_results.items():\n",
        "    dd[k] = {kk:float(vv) for kk,vv in v.items()}\n",
        "\n",
        "  fname = f\"detoxify_{model_type}_{data_type}.json\"\n",
        "  save_to_json(dd, fname)"
      ],
      "metadata": {
        "id": "8q0dfbD69YFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify images\n",
        "\n",
        "Reference:\n",
        "- https://github.com/woctezuma/stable-diffusion-safety-checker"
      ],
      "metadata": {
        "id": "eEUVaQ5eNpop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "XuOdQKFlrqrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image dataset"
      ],
      "metadata": {
        "id": "JFfWqVrtAhNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "from torchvision.datasets.folder import default_loader, is_image_file\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "@functools.lru_cache\n",
        "def get_image_paths(path):\n",
        "    paths = []\n",
        "    for _dirpath, _dirnames, filenames in os.walk(path):\n",
        "        paths.extend([str(Path(_dirpath) / filename) for filename in filenames])\n",
        "    return sorted([fn for fn in paths if is_image_file(fn)])\n",
        "\n",
        "class ImageFolder:\n",
        "\n",
        "    def __init__(self, path, transform=None, loader=default_loader):\n",
        "        self.samples = get_image_paths(path)\n",
        "        self.loader = loader\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        assert 0 <= idx < len(self)\n",
        "        img = self.loader(self.samples[idx])\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return to_pil_image(img)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n"
      ],
      "metadata": {
        "id": "2eIyVJS0xTo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform"
      ],
      "metadata": {
        "id": "SF5TmuMol_1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "def get_target_image_size(resize_size=256, keep_ratio=True):\n",
        "    return resize_size if keep_ratio else (resize_size, resize_size)\n",
        "\n",
        "def get_transform(\n",
        "    resize_size=256,\n",
        "    keep_ratio=True,\n",
        "    interpolation=transforms.InterpolationMode.BICUBIC,\n",
        "):\n",
        "    transforms_list = [\n",
        "        transforms.Resize(\n",
        "            get_target_image_size(resize_size, keep_ratio),\n",
        "            interpolation=interpolation,\n",
        "        ),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        "    return transforms.Compose(transforms_list)"
      ],
      "metadata": {
        "id": "IDEqBKxcl52k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loader"
      ],
      "metadata": {
        "id": "rtIgqoOMAiss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for data loader. Allows to have img of different size\"\"\"\n",
        "    return batch\n",
        "\n",
        "def get_dataloader(\n",
        "    data_dir,\n",
        "    transform = get_transform(),\n",
        "    batch_size=8,\n",
        "    collate_fn=collate_fn,\n",
        "):\n",
        "    dataset = ImageFolder(data_dir, transform=transform)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "SVGdjWDpAI31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run"
      ],
      "metadata": {
        "id": "06l8BxR1r42L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline"
      ],
      "metadata": {
        "id": "UnyQ_Yk1AfdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# https://huggingface.co/Falconsai/nsfw_image_detection\n",
        "pipe = pipeline(\"image-classification\",\n",
        "                model=\"Falconsai/nsfw_image_detection\",\n",
        "                device=\"cuda\")"
      ],
      "metadata": {
        "id": "FsKH49q-NYca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the workflow"
      ],
      "metadata": {
        "id": "0ZC14qPsAoZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# For my use case, this cell required ~ 25 minutes.\n",
        "data_path = \"img/\"\n",
        "batch_size = 8\n",
        "\n",
        "sample_fnames = []\n",
        "safety_scores = []\n",
        "\n",
        "loader = get_dataloader(data_path, batch_size = batch_size)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for ii, images in enumerate(tqdm(loader)):\n",
        "    out = pipe(images)\n",
        "\n",
        "    sample_fnames += [\n",
        "        loader.dataset.samples[ii * batch_size + jj]\n",
        "        for jj in range(len(out))\n",
        "    ]\n",
        "\n",
        "    for dd in out:\n",
        "      safety_scores += [ d[\"score\"] for d in dd\n",
        "                        if d[\"label\"] == \"normal\" ]"
      ],
      "metadata": {
        "id": "lci9uvzyivKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the results\n",
        "\n",
        "Collate the IDs with the scores. At the same time, display the worst offenders."
      ],
      "metadata": {
        "id": "gOEU-e1WAsh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\">>> Saving safety scores...\")\n",
        "fname = get_output_fname(pipe, suffix=\"_safety_scores\", ext=\".pth\")\n",
        "v = torch.asarray(safety_scores, dtype=torch.float16)\n",
        "torch.save(v, fname)"
      ],
      "metadata": {
        "id": "3bKscY9_FGr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(\">>> Saving image paths...\")\n",
        "fname = \"img_list.json\"\n",
        "save_to_json(sample_fnames, fname)"
      ],
      "metadata": {
        "id": "sDcIaTS1F9pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapy as media\n",
        "\n",
        "safety_score_threshold = 0.005\n",
        "img_size = (128, 128)\n",
        "\n",
        "for image_path, safety_score in sorted(\n",
        "    zip(sample_fnames, safety_scores),\n",
        "    key=lambda x: x[1]):\n",
        "  member_id = get_member_id(image_path)\n",
        "\n",
        "  if safety_score < safety_score_threshold:\n",
        "    image = media.read_image(image_path)\n",
        "    image = media.resize_image(image, img_size)\n",
        "\n",
        "    print(f\"{member_id} {safety_score:.2}\")\n",
        "    media.show_image(image)\n"
      ],
      "metadata": {
        "id": "7-8R275U0FkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check results obtained with Stable Diffusion Safety Checker\n",
        "\n",
        "- https://github.com/woctezuma/stable-diffusion-safety-checker"
      ],
      "metadata": {
        "id": "La6RU0hMO0-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/img/bad_concepts_scores.pth\n",
        "!curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/img/img_list.json"
      ],
      "metadata": {
        "id": "Fn5VKPqOMv2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "paths = load_from_json(\"img_list.json\")\n",
        "\n",
        "scores = torch.load(\"bad_concepts_scores.pth\")\n",
        "scores[scores<=0] = 0"
      ],
      "metadata": {
        "id": "nDDmQE_ysZCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapy as media\n",
        "\n",
        "CONCEPT_ID_OF_INTEREST = 3\n",
        "NUM_DISPLAYED_RESULTS = 25\n",
        "\n",
        "DISPLAY_SIZE = (128, 128)\n",
        "\n",
        "vec = scores[:,CONCEPT_ID_OF_INTEREST]\n",
        "# To sum over all the concepts:\n",
        "# vec = scores.sum(dim=1)\n",
        "\n",
        "d = {k:v for k,v in zip(paths, vec)}\n",
        "\n",
        "counter = 0\n",
        "\n",
        "for k,v in sorted(d.items(), key=lambda x: x[1], reverse=True):\n",
        "  print(f\"{k} | score: {v:.2} for concept n°{CONCEPT_ID_OF_INTEREST}\")\n",
        "  media.show_image(media.resize_image(media.read_image(k), DISPLAY_SIZE))\n",
        "\n",
        "  counter += 1\n",
        "\n",
        "  if v <=0 or NUM_DISPLAYED_RESULTS < counter:\n",
        "    break"
      ],
      "metadata": {
        "id": "f2sp33SVNGt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify texts\n",
        "\n",
        "- https://huggingface.co/unitary/toxic-bert\n",
        "- https://github.com/unitaryai/detoxify"
      ],
      "metadata": {
        "id": "OOTXQzKkA8pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detoxify import Detoxify\n",
        "\n",
        "model_index = 2\n",
        "model_types = [\"original\", \"unbiased\", \"multilingual\"]\n",
        "\n",
        "model_type = model_types[model_index]\n",
        "print(model_type)\n",
        "\n",
        "text_model = Detoxify(model_type)"
      ],
      "metadata": {
        "id": "RNPe6FHD7MV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bios_dict = load_from_json(\"bios.json\")\n",
        "start_from_scratch = False\n",
        "\n",
        "if start_from_scratch:\n",
        "  results = {}\n",
        "\n",
        "counter = 0\n",
        "\n",
        "for member, bio in bios_dict.items():\n",
        "  if member not in results:\n",
        "    results[member] = text_model.predict(bio)\n",
        "\n",
        "  counter += 1\n",
        "\n",
        "  if counter % 100 == 0:\n",
        "    print(f'{counter}/{len(bios_dict)}')\n",
        "\n",
        "save_detoxify_results(results, model_type, data_type = \"bios\")"
      ],
      "metadata": {
        "id": "WfcSF68d8jxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "members_dict = load_from_json(\"members.json\")\n",
        "nickname_fields = [\"display_name\", \"global_name\", \"name\", \"nick\"]\n",
        "start_from_scratch = False\n",
        "\n",
        "if start_from_scratch:\n",
        "  results_for_nicknames = {}\n",
        "\n",
        "counter = 0\n",
        "\n",
        "for member, metadata in members_dict.items():\n",
        "  if member not in results_for_nicknames:\n",
        "\n",
        "    all_the_nicknames = list(set([metadata[k] for k in nickname_fields if metadata[k]]))\n",
        "    input_text = ' '.join(all_the_nicknames)\n",
        "\n",
        "    results_for_nicknames[member] = text_model.predict(input_text)\n",
        "\n",
        "  counter += 1\n",
        "\n",
        "  if counter % 100 == 0:\n",
        "    print(f'{counter}/{len(members_dict)}')"
      ],
      "metadata": {
        "id": "L7eCh_5i6mqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}