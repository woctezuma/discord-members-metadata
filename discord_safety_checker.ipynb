{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "AOetn6xSNb68",
        "RMgR2SgkNmDC",
        "izHCcUs0eIoJ",
        "eZTDk2I9KMVA"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Filter inappropriate content\n",
        "\n",
        "- https://github.com/woctezuma/discord-members-metadata"
      ],
      "metadata": {
        "id": "QAF5wev8M7fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages"
      ],
      "metadata": {
        "id": "AOetn6xSNb68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet transformers mediapy"
      ],
      "metadata": {
        "id": "hydcX-K-FVhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the image dataset"
      ],
      "metadata": {
        "id": "RMgR2SgkNmDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "for i in range(1, 3):\n",
        "  fname = f\"img_{i}.zip\"\n",
        "\n",
        "  !curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/img/{fname}\n",
        "  !unzip -qq {fname}"
      ],
      "metadata": {
        "id": "SL7A0j_WNhnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the text datasets"
      ],
      "metadata": {
        "id": "izHCcUs0eIoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "!curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/bio/bios.json\n",
        "!curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/metadata/members.json"
      ],
      "metadata": {
        "id": "MTW4Yo7keMXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define utils"
      ],
      "metadata": {
        "id": "eZTDk2I9KMVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def save_to_json(data, fname):\n",
        "  with Path(fname).open('w') as f:\n",
        "    json.dump(data, f, indent=True)\n",
        "\n",
        "def load_from_json(fname):\n",
        "  with Path(fname).open() as f:\n",
        "    data = json.load(f)\n",
        "  return data\n",
        "\n",
        "def safe_load_from_json(fname):\n",
        "  try:\n",
        "    data = load_from_json(fname)\n",
        "  except FileNotFoundError:\n",
        "    data = {}\n",
        "  return data"
      ],
      "metadata": {
        "id": "h-CfckeOKOJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def get_member_id(image_path):\n",
        "  return Path(image_path).stem"
      ],
      "metadata": {
        "id": "DlczHCyo1FuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output_fname(pipe, suffix = \"\", ext = \".json\"):\n",
        "  return pipe.model.name_or_path.replace('/', '_') + f'{suffix}{ext}'"
      ],
      "metadata": {
        "id": "F7tpp7ZLesfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify images\n",
        "\n",
        "Reference:\n",
        "- https://github.com/woctezuma/stable-diffusion-safety-checker"
      ],
      "metadata": {
        "id": "eEUVaQ5eNpop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "JFfWqVrtAhNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "from torchvision.datasets.folder import default_loader, is_image_file\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "@functools.lru_cache\n",
        "def get_image_paths(path):\n",
        "    paths = []\n",
        "    for _dirpath, _dirnames, filenames in os.walk(path):\n",
        "        paths.extend([str(Path(_dirpath) / filename) for filename in filenames])\n",
        "    return sorted([fn for fn in paths if is_image_file(fn)])\n",
        "\n",
        "class ImageFolder:\n",
        "\n",
        "    def __init__(self, path, transform=None, loader=default_loader):\n",
        "        self.samples = get_image_paths(path)\n",
        "        self.loader = loader\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        assert 0 <= idx < len(self)\n",
        "        img = self.loader(self.samples[idx])\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return to_pil_image(img)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n"
      ],
      "metadata": {
        "id": "2eIyVJS0xTo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform"
      ],
      "metadata": {
        "id": "SF5TmuMol_1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "def get_target_image_size(resize_size=256, keep_ratio=True):\n",
        "    return resize_size if keep_ratio else (resize_size, resize_size)\n",
        "\n",
        "def get_transform(\n",
        "    resize_size=256,\n",
        "    keep_ratio=True,\n",
        "    interpolation=transforms.InterpolationMode.BICUBIC,\n",
        "):\n",
        "    transforms_list = [\n",
        "        transforms.Resize(\n",
        "            get_target_image_size(resize_size, keep_ratio),\n",
        "            interpolation=interpolation,\n",
        "        ),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        "    return transforms.Compose(transforms_list)"
      ],
      "metadata": {
        "id": "IDEqBKxcl52k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loader"
      ],
      "metadata": {
        "id": "rtIgqoOMAiss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for data loader. Allows to have img of different size\"\"\"\n",
        "    return batch\n",
        "\n",
        "def get_dataloader(\n",
        "    data_dir,\n",
        "    transform = get_transform(),\n",
        "    batch_size=8,\n",
        "    collate_fn=collate_fn,\n",
        "):\n",
        "    dataset = ImageFolder(data_dir, transform=transform)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "SVGdjWDpAI31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline"
      ],
      "metadata": {
        "id": "UnyQ_Yk1AfdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# https://huggingface.co/Falconsai/nsfw_image_detection\n",
        "pipe = pipeline(\"image-classification\",\n",
        "                model=\"Falconsai/nsfw_image_detection\",\n",
        "                device=\"cuda\")"
      ],
      "metadata": {
        "id": "FsKH49q-NYca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the workflow"
      ],
      "metadata": {
        "id": "0ZC14qPsAoZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# For my use case, this cell required ~ 25 minutes.\n",
        "data_path = \"img/\"\n",
        "batch_size = 8\n",
        "\n",
        "sample_fnames = []\n",
        "safety_scores = []\n",
        "\n",
        "loader = get_dataloader(data_path, batch_size = batch_size)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for ii, images in enumerate(tqdm(loader)):\n",
        "    out = pipe(images)\n",
        "\n",
        "    sample_fnames += [\n",
        "        loader.dataset.samples[ii * batch_size + jj]\n",
        "        for jj in range(len(out))\n",
        "    ]\n",
        "\n",
        "    for dd in out:\n",
        "      safety_scores += [ d[\"score\"] for d in dd\n",
        "                        if d[\"label\"] == \"normal\" ]"
      ],
      "metadata": {
        "id": "lci9uvzyivKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collate the IDs with the scores. At the same time, display the worst offenders."
      ],
      "metadata": {
        "id": "gOEU-e1WAsh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\">>> Saving safety scores...\")\n",
        "fname = get_output_fname(pipe, suffix=\"_safety_scores\", ext=\".pth\")\n",
        "torch.save(torch.asarray(safety_scores, dtype=torch.float16), fname)"
      ],
      "metadata": {
        "id": "3bKscY9_FGr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(\">>> Saving image paths...\")\n",
        "fname = \"img_list.json\"\n",
        "with Path(fname).open(\"w\") as f:\n",
        "    json.dump(sample_fnames, f)"
      ],
      "metadata": {
        "id": "sDcIaTS1F9pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapy as media\n",
        "\n",
        "safety_score_threshold = 0.005\n",
        "img_size = (128, 128)\n",
        "\n",
        "aggregate = {}\n",
        "for image_path, safety_score in sorted(\n",
        "    zip(sample_fnames, safety_scores),\n",
        "    key=lambda x: x[1]):\n",
        "  member_id = get_member_id(image_path)\n",
        "\n",
        "  aggregate[member_id] = safety_score\n",
        "\n",
        "  if safety_score < safety_score_threshold:\n",
        "    image = media.read_image(image_path)\n",
        "    image = media.resize_image(image, img_size)\n",
        "\n",
        "    print(f\"{member_id} {safety_score:.2}\")\n",
        "    media.show_image(image)\n",
        "\n",
        "save_to_json(aggregate,\n",
        "             get_output_fname(pipe))"
      ],
      "metadata": {
        "id": "7-8R275U0FkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Stable Diffusion Safety Checker\n",
        "\n",
        "- https://github.com/woctezuma/stable-diffusion-safety-checker"
      ],
      "metadata": {
        "id": "La6RU0hMO0-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -OL https://github.com/woctezuma/discord-members-metadata/releases/download/img/bad_concepts.json"
      ],
      "metadata": {
        "id": "Fn5VKPqOMv2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapy as media\n",
        "\n",
        "NUM_CONCEPTS_THRESHOLD = 5\n",
        "DISPLAY_SIZE = (128, 128)\n",
        "\n",
        "data = load_from_json(\"bad_concepts.json\")\n",
        "d = {k:v for k,v in data.items() if len(v)>0}\n",
        "\n",
        "for k,v in sorted(d.items(), key=lambda x: len(x[1]), reverse=True):\n",
        "  print(f\"{k} {len(v)}\")\n",
        "  media.show_image(media.resize_image(media.read_image(k), DISPLAY_SIZE))\n",
        "  if len(v)<NUM_CONCEPTS_THRESHOLD:\n",
        "    break"
      ],
      "metadata": {
        "id": "f2sp33SVNGt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify texts\n",
        "\n",
        "TODO"
      ],
      "metadata": {
        "id": "OOTXQzKkA8pz"
      }
    }
  ]
}